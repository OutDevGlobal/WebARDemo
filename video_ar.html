<!DOCTYPE html>

<html>
  <head>
    <title>Gesture Interactions - A-Frame & AR.js</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="stylesheet" href="styles.css">
    <!-- Import the component -->
    <script src="./three.min.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    <!-- <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script> -->
    <!-- <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script> -->
    <!-- <script src="https://unpkg.com/aframe-look-at-component@0.8.0/dist/aframe-look-at-component.min.js"></script> -->
    <!-- <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script> -->
    <!-- <script src="https://gftruj.github.io/webzamples/aframe/controls/oculus-thumbstick-controls.js"></script> -->
    <!-- <script src="https://rawgit.com/fernandojsg/aframe-teleport-controls/master/dist/aframe-teleport-controls.min.js"></script> -->
    <!-- <script src="gesture-detector.js"></script> -->
    <!-- <script src="gesture-handler.js"></script> -->
    <!-- <script src="dynamicPlaces.js"></script> -->
    <!-- Entrada : 20.646506, -103.409236 -->
    <!-- Lobby : 20.6465648,-103.4091853 -->
    <!-- -->

  </head>

  <body style='margin: 0; overflow: hidden;'>

    <model-viewer id="model-viewer"
                  src="./TV.glb"
                  ar ar_preferred="3D"
                  ar-modes="webxr scene-viewer quick-look"
                  auto-rotate="true"
                  autoplay="true"
                  camera-controls
                  touch-action="pan-y"
                  alt="A 3D model of an astronaut"
    >
        <button id="arCustomButton" slot="ar-button" style="background-color: white; border-radius: 4px; border: none; position: relative; top: 16px; right: 16px; ">
          ðŸ‘‹ Activar Realidad Aumentada
        </button>
    </model-viewer>
    <video id="vidOreo" crossorigin="anonymous" src='./demoOreo.mp4' >
        <source src="./demoOreo.mp4" type="video/mp4">
    </video>



    <script type="module">
      //import * as THREE from 'three';
      /* Three JS Code For Texture With Video */
      const video = document.getElementById( 'vidOreo' );
      video.play();
      const videoTexture = new THREE.VideoTexture( video );
      const modelViewer = document.querySelector('model-viewer')
      const plane = new THREE.PlaneGeometry(1, 1);
      const material = new THREE.MeshBasicMaterial({
        color: 0xffffff,
        map: videoTexture,
        side: THREE.DoubleSide,
      });
      const mesh = new THREE.Mesh(plane, material);
      const currentScene = Object.getOwnPropertySymbols(modelViewer)[18];
      mesh.position.set(0, 1, 0);
      mesh.scale.set(10, 10, 1);
      mesh.rotateY(1);

      modelViewer[currentScene].add(mesh)

      const arStatusChecker =  () => {
        document.querySelector("model-viewer").addEventListener('ar-status', (event) => {
          if(event.detail.status === 'failed'){
            const error = document.querySelector("#error");
            error.classList.remove('hide');
            error.addEventListener('transitionend',(event) => {
              error.classList.add('hide');
            });
          }
        });
      }

      const renderAR = async () =>{
        console.log("AR Function")

        console.log(modelViewer.loaded)
        if(modelViewer.loaded){

          const materials = modelViewer.model.materials;

          materials.map(async (material) => {
            return await createAndApplyVideoTexture('normalTexture', material)
          })

          document.getElementById('arCustomButton').addEventListener('click', () => {});

          setTimeout(
            modelViewer.querySelector('button#arCustomButton').click(),
            50000
          )
        }else {
          setTimeout(renderAR, 1);
        }
      }
      function docReady(fn) {
          // see if DOM is already available
          arStatusChecker()
          if (document.readyState === "complete" || document.readyState === "interactive") {
              // call on next available tick
              renderAR();
          } else {
              document.addEventListener("DOMContentLoaded", fn);
          }
      }
      const createAndApplyVideoTexture = async (channel, material) => {

        const texture = await modelViewer.createTexture('./arcaddy_logo_for_qr.png');
        material[channel].setTexture(texture);
      }
      const createAndApplyTexture = async (channel, event, material) => {
        if (event.target.value === "None") {
          // Clears the texture.
          material[channel].setTexture(null);
          // Display the names values
          // textureName.innerText = "None";
          // imageName.innerText = "None";
        } else if (event.target.value) {
          // Creates a new texture.
          const texture = await modelViewer.createTexture(event.target.value);
          // Set the texture name
          texture.name = event.target.options[event.target.selectedIndex].text.replace(/ /g, "_").toLowerCase();
          // Applies the new texture to the specified channel.
          material[channel].setTexture(videoTexture);
          // Display the names values
          // textureName.innerText = texture.name;
          // imageName.innerText = texture.source.name;
        }
      }



      window.addEventListener('load', docReady, false )


    </script>

  </body>
</html>